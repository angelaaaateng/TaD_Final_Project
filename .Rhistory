anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
### need to convert the data structure to a wide format
emo_box = emotions %>%
spread(sentiment, percent, fill=0) %>%
ungroup()
### color scheme for the box plots (This step is optional)
cols  <- colorRampPalette(brewer.pal(7, "Set3"), alpha=TRUE)(8)
title <- cat("Distribution of emotion words count in", name, 'transcripts')
boxplot2(emo_box[,c(2:9)], col=cols, lty=1, shrink=0.8, textcolor="red",
xlab="Emotion Terms", ylab="Emotion words count (%)", main=title)
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Date") +
ylab("Emotion words count (%)")# +
ggtitle(name)
#
#
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
}
calculate_emotion(US, 'US')
calculate_emotion <- function(matches, name){
# total_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   group_by(date) %>%
#   summarize(total= n()) %>%
#   ungroup()
#
# emotion_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   filter(!(sentiment == "negative" | sentiment == "positive" | sentiment == "NA")) %>%
#   group_by(date) %>%
#   summarize(emotions= n()) %>%
#   ungroup()
#
# emotions_to_total_words <- total_words_count %>%
#   left_join(emotion_words_count, by="date") %>%
#   mutate(percent_emotions=round((emotions/total)*100,1))
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ### need to convert the data structure to a wide format
# emo_box = emotions %>%
#   spread(sentiment, percent, fill=0) %>%
#   ungroup()
# ### color scheme for the box plots (This step is optional)
# cols  <- colorRampPalette(brewer.pal(7, "Set3"), alpha=TRUE)(8)
# title <- cat("Distribution of emotion words count in", name, 'transcripts')
# boxplot2(emo_box[,c(2:9)], col=cols, lty=1, shrink=0.8, textcolor="red",
#          xlab="Emotion Terms", ylab="Emotion words count (%)", main=title)
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Date") +
ylab("Emotion words count (%)")# +
ggtitle(name)
#
#
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
}
calculate_emotion(US, 'US')
calculate_emotion <- function(matches, name){
# total_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   group_by(date) %>%
#   summarize(total= n()) %>%
#   ungroup()
#
# emotion_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   filter(!(sentiment == "negative" | sentiment == "positive" | sentiment == "NA")) %>%
#   group_by(date) %>%
#   summarize(emotions= n()) %>%
#   ungroup()
#
# emotions_to_total_words <- total_words_count %>%
#   left_join(emotion_words_count, by="date") %>%
#   mutate(percent_emotions=round((emotions/total)*100,1))
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ### need to convert the data structure to a wide format
# emo_box = emotions %>%
#   spread(sentiment, percent, fill=0) %>%
#   ungroup()
# ### color scheme for the box plots (This step is optional)
# cols  <- colorRampPalette(brewer.pal(7, "Set3"), alpha=TRUE)(8)
# title <- cat("Distribution of emotion words count in", name, 'transcripts')
# boxplot2(emo_box[,c(2:9)], col=cols, lty=1, shrink=0.8, textcolor="red",
#          xlab="Emotion Terms", ylab="Emotion words count (%)", main=title)
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle("Emotion words expressed in Mr. Buffett's \n annual shareholder letters")
#
#
# ### calculate overall averages and standard deviations for each emotion term
# overall_mean_sd <- emotions %>%
#   group_by(sentiment) %>%
#   summarize(overall_mean=mean(percent), sd=sd(percent))
# ### draw a bar graph with error bars
# ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
#   geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
#   geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
#   xlab("Emotion Terms") +
#   ylab("Emotion words count (%)") +
#   ggtitle(name) +
#   theme(axis.text.x=element_text(angle=45, hjust=1)) +
#   coord_flip( )
}
calculate_emotion(US, 'US')
calculate_emotion <- function(matches, name){
# total_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   group_by(date) %>%
#   summarize(total= n()) %>%
#   ungroup()
#
# emotion_words_count <- matches %>%
#   unnest_tokens(word, text) %>%
#   anti_join(stop_words, by = "word") %>%
#   filter(!grepl('[0-9]', word)) %>%
#   left_join(get_sentiments("nrc"), by = "word") %>%
#   filter(!(sentiment == "negative" | sentiment == "positive" | sentiment == "NA")) %>%
#   group_by(date) %>%
#   summarize(emotions= n()) %>%
#   ungroup()
#
# emotions_to_total_words <- total_words_count %>%
#   left_join(emotion_words_count, by="date") %>%
#   mutate(percent_emotions=round((emotions/total)*100,1))
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ### need to convert the data structure to a wide format
# emo_box = emotions %>%
#   spread(sentiment, percent, fill=0) %>%
#   ungroup()
# ### color scheme for the box plots (This step is optional)
# cols  <- colorRampPalette(brewer.pal(7, "Set3"), alpha=TRUE)(8)
# title <- cat("Distribution of emotion words count in", name, 'transcripts')
# boxplot2(emo_box[,c(2:9)], col=cols, lty=1, shrink=0.8, textcolor="red",
#          xlab="Emotion Terms", ylab="Emotion words count (%)", main=title)
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
#
#
# ### calculate overall averages and standard deviations for each emotion term
# overall_mean_sd <- emotions %>%
#   group_by(sentiment) %>%
#   summarize(overall_mean=mean(percent), sd=sd(percent))
# ### draw a bar graph with error bars
# ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
#   geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
#   geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
#   xlab("Emotion Terms") +
#   ylab("Emotion words count (%)") +
#   ggtitle(name) +
#   theme(axis.text.x=element_text(angle=45, hjust=1)) +
#   coord_flip( )
}
calculate_emotion(US, 'US')
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
}
calculate_emotion(US, 'US')
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
p <- ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
fname = cat(name, 'overall.png')
ggsave(fname, plot = p)
}
for(i in names){
data <- matches[matches$country == i,]
calculate_emotion(data, i)
}
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
p <- ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
fname = paste0(name, 'overall.png')
ggsave(fname, plot = p)
}
for(i in names){
data <- matches[matches$country == i,]
calculate_emotion(data, i)
}
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
p <- ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
fname = paste0(name, 'over_time.png')
ggsave(fname, plot = p)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
p <- ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
fname = paste0(name, 'overall.png')
ggsave(fname, plot = p)
}
for(i in names){
data <- matches[matches$country == i,]
calculate_emotion(data, i)
}
rm(list=ls())
load('full_data.Rda')
rm(list=ls())
load('full_data.Rda')
require(tidyverse)
require(tidytext)
require(RColorBrewer)
require(gplots)
theme_set(theme_bw(12))
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
p <- ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
fname = paste0(name, 'over_time.png')
ggsave(fname, plot = p)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
p <- ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
fname = paste0(name, 'overall.png')
ggsave(fname, plot = p)
}
for(i in names){
data <- matches[matches$country == i,]
calculate_emotion(data, i)
}
rm(list=ls())
load('full_data.Rda')
# install.packages("RColorBrewer")
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("gplots")
install.packages('textdata')
rm(list=ls())
load('full_data.Rda')
require(tidyverse)
require(tidytext)
require(RColorBrewer)
require(gplots)
theme_set(theme_bw(12))
calculate_emotion <- function(matches, name){
### pull emotion words and aggregate by year and emotion terms
emotions <- matches %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word)) %>%
left_join(get_sentiments("nrc"), by = "word") %>%
filter(!(sentiment == "negative" | sentiment == "positive")) %>%
group_by(date, sentiment) %>%
summarize( freq = n()) %>%
mutate(percent=round(freq/sum(freq)*100)) %>%
select(-freq) %>%
ungroup()
# ## daily line chart
p <- ggplot(emotions, aes(x=date, y=percent, color=sentiment, group=sentiment)) +
geom_line(size=1) +
geom_point(size=0.5) +
xlab("Year") +
ylab("Emotion words count (%)") +
ggtitle(name)
fname = paste0(name, 'over_time.png')
ggsave(fname, plot = p)
# ### calculate overall averages and standard deviations for each emotion term
overall_mean_sd <- emotions %>%
group_by(sentiment) %>%
summarize(overall_mean=mean(percent), sd=sd(percent))
### draw a bar graph with error bars
p <- ggplot(overall_mean_sd, aes(x = reorder(sentiment, -overall_mean), y=overall_mean)) +
geom_bar(stat="identity", fill="darkgreen", alpha=0.7) +
geom_errorbar(aes(ymin=overall_mean-sd, ymax=overall_mean+sd), width=0.2,position=position_dodge(.9)) +
xlab("Emotion Terms") +
ylab("Emotion words count (%)") +
ggtitle(name) +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
coord_flip( )
fname = paste0(name, 'overall.png')
ggsave(fname, plot = p)
}
names <- c('US', 'UK', 'NZ', 'CA', 'AU')
for(i in names){
data <- matches[matches$country == i,]
calculate_emotion(data, i)
}
save.image('emotion_workspace.RData')
